# ğŸ™ï¸ Transcription Backend

A powerful and scalable audio transcription service with multi-model support for Whisper and Gemini models.

## ğŸ“‹ Overview

This backend service provides a robust API for transcribing audio files, analyzing the transcription results, and managing the status of transcription jobs. It uses FastAPI for the web framework and Celery for handling long-running transcription tasks asynchronously.

## ğŸ—‚ï¸ Project Structure
transcription_backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ transcribe.py    # Endpoints for transcription requests
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze.py       # Endpoints for analysis of transcribed content
â”‚   â”‚   â”‚   â””â”€â”€ status.py        # Endpoints for checking job status
â”‚   â”‚   â””â”€â”€ deps.py              # Dependency injection utilities
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py            # Application configuration
â”‚   â”‚   â””â”€â”€ logging_config.py    # Logging setup
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ audio_utils.py       # Audio processing utilities
â”‚   â”‚   â”œâ”€â”€ whisper_transcriber.py  # OpenAI Whisper integration
â”‚   â”‚   â”œâ”€â”€ gemini_transcriber.py   # Google Gemini integration
â”‚   â”‚   â””â”€â”€ job_manager.py       # Job queue management
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â””â”€â”€ tasks.py             # Background task definitions
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py           # Pydantic models for data validation
â”‚   â””â”€â”€ main.py                  # Application entry point
â”œâ”€â”€ index.html                   # Main frontend page
â”œâ”€â”€ requirements.txt             # Project dependencies
â””â”€â”€ README.md                    # This documentation

## ğŸš€ Getting Started

### Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

### Install dependencies
pip install -r requirements.txt

### Set up environment variables

# Create a .env file with your configuration
cp .env.example .env
# Edit .env with your settings

## ğŸ–¥ï¸ Running the Application

### Start the API Server

uvicorn app.main:app --reload --host 0.0.0.0 --port 8001

### Simple File Server (for development)

If you need a simple file server for testing or development:

python -m http.server 8080

## ğŸŒ Accessing the Application

Once the server is running, you can access:

- File server (if running): http://localhost:8080/